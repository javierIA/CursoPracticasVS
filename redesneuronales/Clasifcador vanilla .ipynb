{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (4.8.2)\n",
      "Requirement already satisfied: tqdm in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (4.64.1)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (1.0.0)\n",
      "Requirement already satisfied: psutil in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (5.9.4)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (3.19.6)\n",
      "Requirement already satisfied: dm-tree in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: absl-py in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: promise in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: click in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (8.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (2.28.2)\n",
      "Requirement already satisfied: dill in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (0.3.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (1.12.0)\n",
      "Requirement already satisfied: toml in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: wrapt in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (1.24.2)\n",
      "Requirement already satisfied: termcolor in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-datasets) (2.2.0)\n",
      "Requirement already satisfied: zipp in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.13.0)\n",
      "Requirement already satisfied: importlib_resources in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (5.10.2)\n",
      "Requirement already satisfied: typing_extensions in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.14)\n",
      "Requirement already satisfied: six in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.58.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:38:52.540534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 14:38:52.700540: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-14 14:38:52.705386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:38:52.705413: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-14 14:38:54.105196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:38:54.105344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:38:54.105359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:38:57.508610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:38:57.508646: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 14:38:57.508678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (javierfia-latitude3520): /proc/driver/nvidia/version does not exist\n",
      "2023-02-14 14:38:57.509223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "datos,metadatos=tfds.load(name='fashion_mnist',as_supervised=True,with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    full_name='fashion_mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    data_path='/home/javieria/tensorflow_datasets/fashion_mnist/3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=29.45 MiB,\n",
       "    dataset_size=36.42 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test=datos['train'],datos['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_class= metadatos.features['label'].names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(imagenes, etiquetas):\n",
    "  imagenes = tf.cast(imagenes, tf.float32)\n",
    "  imagenes /= 255 #Aqui lo pasa de 0-255 a 0-1\n",
    "  return imagenes, etiquetas\n",
    "\n",
    "data_train=data_train.map(normalizar)\n",
    "data_test=data_test.map(normalizar)\n",
    "\n",
    "data_train=data_train.cache()\n",
    "data_test=data_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:39:12.980021: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-02-14 14:39:12.980202: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for imagen,etiqueta in data_train.take(1):\n",
    "  break\n",
    "imagen=imagen.numpy().reshape((28,28))\n",
    " \n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(imagen,cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    " tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    " tf.keras.layers.Dense(50,activation=tf.nn.relu),\n",
    " tf.keras.layers.Dense(50,activation=tf.nn.relu),\n",
    " tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "num_examples=metadatos.splits['train'].num_examples\n",
    "num_pruebas=metadatos.splits['test'].num_examples\n",
    "print(num_examples)\n",
    "print(num_pruebas)\n",
    "size_batch=32\n",
    "datosdeentrenamiento=data_train.repeat().shuffle(num_examples).batch(size_batch)\n",
    "datosdetest=data_test.batch(size_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 4ms/step - loss: 0.5179 - accuracy: 0.8165\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3865 - accuracy: 0.8602\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3491 - accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3293 - accuracy: 0.8797\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3107 - accuracy: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3edc81dd80>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "model.fit(datosdeentrenamiento,epochs=5,steps_per_epoch=math.ceil(num_examples/size_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_2_input'), name='flatten_2_input', description=\"created by layer 'flatten_2_input'\"), but it was called on an input with incompatible shape (None, 28, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:37:21.868574: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-02-14 14:37:21.868791: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_2_input'), name='flatten_2_input', description=\"created by layer 'flatten_2_input'\"), but it was called on an input with incompatible shape (None, 28, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m imagenes\u001b[39m=\u001b[39mimagenes\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m etiquetas\u001b[39m=\u001b[39metiquetas\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m----> 4\u001b[0m predicciones\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mpredict(imagenes)\n",
      "File \u001b[0;32m~/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file74dh19ae.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/javieria/Documents/cursos/CursoPracticasVS/.env/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "for imagenes,etiquetas in data_test.take(1):\n",
    "  imagenes=imagenes.numpy()\n",
    "  etiquetas=etiquetas.numpy()\n",
    "  predicciones=model.predict(imagenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:25:09.536614: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-02-14 14:25:09.536926: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img,lab\u001b[39m=\u001b[39m data_test\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m img\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img)\n\u001b[1;32m      4\u001b[0m prediccion\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(img)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74f7bda608e392dc1711e6b3390746ebc507fb0f167cea715d57bdd2727069b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
